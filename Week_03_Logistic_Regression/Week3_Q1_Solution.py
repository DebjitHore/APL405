# -*- coding: utf-8 -*-
"""Week3_Template_LR.ipynb
Automatically generated by Colaboratory.
# Logistic  Regression
Fill the blank spaces as required. 
Do not change name of any class, method name.
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from scipy import optimize
import pandas as pd

class lr:
    # Data cleaning and finding the mean of the column titled "MaxTemp"
    def data_clean(self,data):
        data.RainTomorrow = pd.Series(np.where(data.RainTomorrow.values == 'Yes', 1, 0))
        
        data = data.select_dtypes(exclude=['object'])
        
        data.fillna(data.mean(), inplace=True)
        
        y1 = data.RainTomorrow.values
        X1 = data.drop('RainTomorrow', axis=1)
                    
        X1 = (X1 - np.min(X1)) / (np.max(X1) - np.min(X1))
        
        mean = X1["MaxTemp"].mean()
        
        return X1, y1, mean

class costing:
    # define the function needed to evaluate cost function
    # Input 'z' could be a scalar or a 1D vector
    def sigmoid(self,z):
        
        g = 1/(1 + np.exp(-z))
        
        return g
    
    # Regularized cost function definition
    def costFunctionReg(self,w,X,y,lambda_):
        
        m,n = np.shape(X)

        h = self.sigmoid(np.dot(X,w))

        J = -np.dot(y,np.log(h))*(1/m) - np.dot((1-y),np.log(1-h))*(1/m) + (lambda_/(2*m))*(np.sum(w[1:]**2))

        grad = np.transpose(X)@(h - y)/m + np.insert(w[1:],0,0)*lambda_/m

        return J, grad
    
    # Prediction based on trained model
    # Use sigmoid function to calculate probability rounded off to either 0 or 1
    def predict(self,w,X):
        
        m = np.shape(X)[0]
        p = []
        for i in range(m):
            p.append(round(self.sigmoid(np.dot(w,X[i,:]))))        # 'p' should be a vector of size equal to that of vector 'y'
        return p
    
    # Optimization defintion
    def minCostFun(self, w_ini, X_train, y_train, iters):
        # iters - Maximum no. of iterations; X_train - Numpy array
        lambda_ = 0.1         # Regularization parameter

        m, n = X_train.shape
        X_train = np.concatenate([np.ones((m, 1)), X_train], axis=1)
        
        options = {'maxiter' : iters}

        res = optimize.minimize(self.costFunctionReg,
                                w_ini,
                                (X_train,y_train,lambda_),
                                jac = True,
                                method='TNC',
                                options=options)
        
        w_opt = np.round(res.x,3)       # Optimized weights rounded off to 3 decimal places
        message = res.message
        print(message)
        print(w_opt)
        
        acrcy = round(np.mean(y_train==self.predict(w_opt,X_train))*100,3)      # Training set accuracy (in %) rounded off to 3 decimal places
        
        return w_opt, acrcy
    
    # Calculate testing accuracy
    def TestingAccu(self, w_opt, X_test, y_test):
        m, n = X_test.shape
        X_test = np.concatenate([np.ones((m, 1)), X_test], axis=1)
        
        p1 = self.predict(w_opt, X_test)
        acrcy_test = np.round(np.mean(p1 == y_test)*100,3)
        
        return acrcy_test